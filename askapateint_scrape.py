# -*- coding: utf-8 -*-
"""askapateint_scrape.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JhCRoCCWWK1k4YQ3qnLqvdth3M8OEJ0S
"""


import pandas as pd
import requests
from bs4 import BeautifulSoup
import numpy as np
from fake_useragent import UserAgent

data = []
for i in range(1,40):
  # print(i)
  url = f'https://www.askapatient.com/viewrating.asp?drug=21436&name=ABILIFY&page={i}'
  user_agent = UserAgent()
  headers = {'User-Agent': user_agent.random}

  # Fetch the webpage content
  webpage = requests.get(url, headers=headers).text
  soup = BeautifulSoup(webpage, 'html.parser')
  tables = soup.find('table', {'class': 'ratingsTable'})
  rows = tables.find_all('td')

  for i in range(0,156,8):
    rating = rows[16+i].text
    reason = rows[17+i].text
    side_effects = rows[18+i].text
    comments = rows[19+i].text
    sex = rows[20+i].text
    age = rows[21+i].text
    duration_dosage = rows[22+i].text
    date_added = rows[23+i].text
    # data.append(comments)
    # print(comments)
    entry = {
          'Rating': rating,
          'Reason': reason,
          'Side Effects': side_effects,
          'Comments': comments,
          'Sex': sex,
          'Age': age,
          'Duration/Dosage': duration_dosage,
          'Date Added': date_added
      }

    data.append(entry)

len(rows)


df = pd.DataFrame(data)


df.to_csv('abilify.csv', index=False)